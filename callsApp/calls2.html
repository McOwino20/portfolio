<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- This adapter normalizes cross-browser differences in WebRTC APIs. Currently necessary in order to support Firefox. -->
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/webrtc-adapter/8.1.2/adapter.min.js"
      integrity="sha512-l40eBFtXx+ve5RryIELC3y6/OM6Nu89mLGQd7fg1C93tN6XrkC3supb+/YiD/Y+B8P37kdJjtG1MT1kOO2VzxA=="
      crossorigin="anonymous"
      referrerpolicy="no-referrer"
    ></script>
  </head>


  <body>

  <div class="grid">
    <h1>Calls Echo Demo</h1>
    <div>
      <h2>Local Stream</h2>
      <video id="local-video" autoplay muted></video>
      <div class="controls">
        <button id="toggle-audio">Mute Audio</button>
        <button id="toggle-video">Turn Off Video</button>
      </div>
    </div>
    <div>
      <h2>Remote Echo Stream</h2>
      <video id="remote-video" autoplay></video>
    </div>
  </div>
  <div class="footer">
    <button id="end-call" class="end-call">End Call</button>
    <p id="status">Status: <span id="connection-status">Not Connected</span></p>
  </div>






    


    <script type="module">
      // This is a class the defines the Calls API interactions.
      // It's not an SDK but a example of how Calls API can be used.


      // This is the App Id provided by the dashboard that identifies this Calls Application.
      const appId = '0798a179cb33d8e6b52df5d6f94d19cf';
      // DO NOT USE YOUR SECRET IN THE BROWSER FOR PRODUCTION. It should be kept and used server-side.
      const appSecret =6624e46b16135c73710a150';


      class CallsApp {
        constructor(appId, basePath = 'https://rtc.live.cloudflare.com/v1') {
          this.prefixPath = `${basePath}/apps/${appId}`;
        }


        async sendRequest(url, body, method = 'POST') {
          const request = {
            method: method,
            mode: 'cors',
            headers: {
              'content-type': 'application/json',
              Authorization: `Bearer ${appSecret}`
            },
            body: JSON.stringify(body)
          };
          const response = await fetch(url, request);
          const result = await response.json();
          return result;
        }


        checkErrors(result, tracksCount = 0) {
          if (result.errorCode) {
            throw new Error(result.errorDescription);
          }
          for (let i = 0; i < tracksCount; i++) {
            if (result.tracks[i].errorCode) {
              throw new Error(
                `tracks[${i}]: ${result.tracks[i].errorDescription}`
              );
            }
          }
        }


        // newSession sends the initial offer and creates a session
        async newSession(offerSDP) {
          const url = `${this.prefixPath}/sessions/new`;
          const body = {
            sessionDescription: {
              type: 'offer',
              sdp: offerSDP
            }
          };
          const result = await this.sendRequest(url, body);
          this.checkErrors(result);
          this.sessionId = result.sessionId;
          return result;
        }


        // newTracks shares local tracks or gets tracks
        async newTracks(trackObjects, offerSDP = null) {
          const url = `${this.prefixPath}/sessions/${this.sessionId}/tracks/new`;
          const body = {
            sessionDescription: {
              type: 'offer',
              sdp: offerSDP
            },
            tracks: trackObjects
          };
          if (!offerSDP) {
            delete body['sessionDescription'];
          }
          const result = await this.sendRequest(url, body);
          this.checkErrors(result, trackObjects.length);
          return result;
        }


        // sendAnswerSDP sends an answer SDP if a renegotiation is required
        async sendAnswerSDP(answer) {
          const url = `${this.prefixPath}/sessions/${this.sessionId}/renegotiate`;
          const body = {
            sessionDescription: {
              type: 'answer',
              sdp: answer
            }
          };
          const result = await this.sendRequest(url, body, 'PUT');
          this.checkErrors(result);
        }
      }


      // Use Cloudflare's STUN server
      self.pc = new RTCPeerConnection({
        iceServers: [
          {
            urls: 'stun:stun.cloudflare.com:3478'
          }
        ],
        bundlePolicy: 'max-bundle'
      });


      // In order to successfully establish a peer connection, we need at least one track to publish.
      // In this case, we create two: video & audio
      const localStream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: true
      });


      // Get the local video element in the HTML and set the source to show local stream
      const localVideoElement = document.getElementById('local-video');
      localVideoElement.srcObject = localStream;


      // Add sendonly trancievers to the PeerConnection
      self.transceivers = localStream.getTracks().map(track =>
        self.pc.addTransceiver(track, {
          direction: 'sendonly'
        })
      );


      // Create a instance of CallsApp (defined below). Please note that this is not an official SDK but just a demo showing the HTML API.
      self.app = new CallsApp(appId);


      // Send the first offer and create a session. The returned sessionId is required to retrieve any track published by this peer
      await self.pc.setLocalDescription(await self.pc.createOffer());
      const newSessionResult = await self.app.newSession(
        self.pc.localDescription.sdp
      );
      await self.pc.setRemoteDescription(
        new RTCSessionDescription(newSessionResult.sessionDescription)
      );


      // Make the peer connection was established
      await new Promise((resolve, reject) => {
        self.pc.addEventListener('iceconnectionstatechange', ev => {
          if (ev.target.iceConnectionState === 'connected') {
            resolve();
          }
          setTimeout(reject, 5000, 'connect timeout');
        });
      });


      // We associate a trackName to a transceiver identified by a mid (media ID). This way the track
      // is remotely reachable by the tuple (sessionId, trackName)
      let trackObjects = self.transceivers.map(transceiver => {
        return {
          location: 'local',
          mid: transceiver.mid,
          trackName: transceiver.sender.track.id
        };
      });


      // Get local description, create a new track, set remote description with the response
      await self.pc.setLocalDescription(await self.pc.createOffer());
      const newLocalTracksResult = await self.app.newTracks(
        trackObjects,
        self.pc.localDescription.sdp
      );
      await self.pc.setRemoteDescription(
        new RTCSessionDescription(newLocalTracksResult.sessionDescription)
      );


      // At this point in code, we are successfully sending local stream to Cloudflare Calls.
      // Now, we will pull the same stream from Cloudflare Calls.


      // Update trackObjects to reference the tracks as "remote"
      trackObjects = trackObjects.map(trackObject => {
        return {
          location: 'remote',
          sessionId: self.app.sessionId,
          trackName: trackObject.trackName
        };
      });


      // Prepare to receive the tracks before asking for them
      const remoteTracksPromise = new Promise(resolve => {
        let tracks = [];
        self.pc.ontrack = event => {
          tracks.push(event.track);
          console.debug(`Got track mid=${event.track.mid}`);
          if (tracks.length >= 2) {
            // remote video & audio are ready
            resolve(tracks);
          }
        };
      });


      // Calls API request to ask for the tracks
      const newRemoteTracksResult = await self.app.newTracks(trackObjects);
      if (newRemoteTracksResult.requiresImmediateRenegotiation) {
        switch (newRemoteTracksResult.sessionDescription.type) {
          case 'offer':
            // We let Cloudflare know we're ready to receive the tracks
            await self.pc.setRemoteDescription(
              new RTCSessionDescription(
                newRemoteTracksResult.sessionDescription
              )
            );
            await self.pc.setLocalDescription(await self.pc.createAnswer());
            await self.app.sendAnswerSDP(self.pc.localDescription.sdp);
            break;
          case 'answer':
            throw new Error('An offer SDP was expected');
        }
      }


      // Once started receiving the tracks (video & audio) send the data to the video tag
      const remoteTracks = await remoteTracksPromise;
      const remoteVideoElement = document.getElementById('remote-video');
      const remoteStream = new MediaStream();
      remoteStream.addTrack(remoteTracks[0]);
      remoteStream.addTrack(remoteTracks[1]);
      remoteVideoElement.srcObject = remoteStream;
    </script>
    <style>
      /* Styles are safe to ignore, just here for demo */

  /* General Styling */
  html {
    color-scheme: light dark;
    font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
    background: #f8f9fa; /* Light gray background for better readability */
    color: #212529; /* Dark text color for better contrast */
    margin: 0;
    padding: 0;
  }

  body {
    padding: 1rem;
    max-width: 1200px;
    margin: 0 auto;
    background: #ffffff;
    border-radius: 8px;
    box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
  }

  h1 {
    font-size: 1.75rem;
    font-weight: 600;
    color: #007bff; /* Use a highlight color for main headings */
    margin-bottom: 1rem;
    text-align: center;
  }

  h2 {
    font-size: 1.25rem;
    font-weight: 500;
    color: #495057; /* Slightly muted color for subheadings */
    margin-bottom: 0.5rem;
    text-align: center;
  }

  video {
    width: 100%;
    border-radius: 8px;
    border: 2px solid #dee2e6; /* Add a border for better separation */
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1); /* Light shadow for depth */
  }

  /* Grid Layout */
  .grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
    gap: 1.5rem;
    margin-top: 1rem;
  }



  .controls {
    margin-top: 0.5rem;
    display: flex;
    justify-content: center;
    gap: 0.5rem;
  }

  button {
    background: #007bff;
    color: #ffffff;
    border: none;
    border-radius: 4px;
    padding: 0.5rem 1rem;
    font-size: 0.9rem;
    cursor: pointer;
    transition: background-color 0.3s ease;
  }

  button:hover {
    background: #0056b3;
  }

  button.end-call {
    background: #dc3545;
  }

  button.end-call:hover {
    background: #a71d2a;
  }

  .footer {
    margin-top: 1rem;
    text-align: center;
  }

  #status {
    margin-top: 0.5rem;
    font-size: 0.9rem;
    color: #495057;
  }

  #connection-status {
    font-weight: bold;
    color: #007bff;
  }

    


      

  /* Responsive Design */
  @media (max-width: 768px) {
    body {
      padding: 0.5rem;
    }

    h1 {
      font-size: 1.5rem;
    }

    h2 {
      font-size: 1rem;
    }
  }

  @media (max-width: 500px) {
    .grid {
      gap: 1rem;
    }
  }
</style>






  <script type="module">
    // Controls for mute/unmute and video toggle
    const toggleAudioButton = document.getElementById("toggle-audio");
    const toggleVideoButton = document.getElementById("toggle-video");
    const endCallButton = document.getElementById("end-call");
    const statusSpan = document.getElementById("connection-status");

    let isAudioEnabled = true;
    let isVideoEnabled = true;

    // Update connection status
    self.pc.addEventListener("iceconnectionstatechange", (event) => {
      statusSpan.textContent = event.target.iceConnectionState;
      if (event.target.iceConnectionState === "disconnected") {
        alert("Connection lost!");
      }
    });

    // Toggle audio
    toggleAudioButton.addEventListener("click", () => {
      localStream.getAudioTracks().forEach((track) => {
        track.enabled = !track.enabled;
      });
      isAudioEnabled = !isAudioEnabled;
      toggleAudioButton.textContent = isAudioEnabled ? "Mute Audio" : "Unmute Audio";
    });

    // Toggle video
    toggleVideoButton.addEventListener("click", () => {
      localStream.getVideoTracks().forEach((track) => {
        track.enabled = !track.enabled;
      });
      isVideoEnabled = !isVideoEnabled;
      toggleVideoButton.textContent = isVideoEnabled ? "Turn Off Video" : "Turn On Video";
    });

    // End call
    endCallButton.addEventListener("click", () => {
      self.pc.close();
      alert("Call ended.");
      window.location.reload();
    });
  </script>
    
  </body>
</html>

